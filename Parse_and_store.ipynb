{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Want to collect your data from the web and store it easily ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook we will create a Data Base in mySQL , parse COT report from CFTC and store it with report date, in 3 steps :\n",
    "\n",
    "### A. Create mySQL Table\n",
    "### B. Parse CFTC website with information required from the Commitment of Trader report, released every Tuesday and Friday\n",
    "### C. Store in DB using SQL query\n",
    "\n",
    "\n",
    "# -------------------------------------\n",
    "\n",
    "#### Some things you should consider before web scraping a website:\n",
    "\n",
    "1.) You should check a site's terms and conditions before you scrape them. \n",
    "\n",
    "2.) Space out your requests so you don't overload the site's server, doing this could get you blocked.\n",
    "\n",
    "3.) Scrapers break after time - web pages change their layout all the time, you'll more than likely have to rewrite your code. \n",
    "\n",
    "4.) Web pages are usually inconsistent, more than likely you'll have to clean up the data after scraping it.\n",
    "\n",
    "5.) Every web page and situation is different, you'll have to spend time configuring your scraper.\n",
    "\n",
    "\n",
    "\n",
    "#### There are three modules we'll need in addition to python are:\n",
    "\n",
    "1.) BeautifulSoup, which you can download by typing: *pip install beautifulsoup4* or *conda install beautifulsoup4* (for the Anaconda distrbution of Python) in your command prompt.\n",
    "\n",
    "2.) lxml , which you can download by typing: *pip install lxml* or *conda install lxml* (for the Anaconda distrbution of Python) in your command prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with our imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series,DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request content from web page\n",
    "result = requests.get(url)\n",
    "c = result.content\n",
    "\n",
    "# Set as Beautiful Soup Object\n",
    "soup = BeautifulSoup(c, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import random\n",
    "import pymysql\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "url = 'http://www.cftc.gov/dea/options/petroleumlof.htm'\n",
    "response = urllib2.urlopen(url)\n",
    "cr = csv.reader(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Create DB to store value of positions of Money Managers in the Crude Oil Futures market\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the Data Base in mySQL with pymsql\n",
    "\n",
    "conn = pymysql.connect(host='127.0.0.1', user='Baptiste',passwd='Kamca2017!', db='scraping')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"USE scraping\")\n",
    "\n",
    "\n",
    "\n",
    "#On cree la table Brent \n",
    "\n",
    "cur.execute(\"CREATE TABLE Volume_OI ( MDATE date NOT NULL,\\\n",
    "                                        FUT_AGGTE_VOL_BRENT FLOAT(15,2),\\\n",
    "                                        BRENT_1 FLOAT(15,2),\\\n",
    "                                        BRENT_OI FLOAT(15,2),\\\n",
    "                                        WTI_OI FLOAT(15,2),\\\n",
    "                                        WTI_Managed_Money_Net FLOAT(15,2),   \\\n",
    "                                        BRENT_Managed_Money_Net FLOAT(15,2),\\\n",
    "                                        WTI_Managed_Money_Long FLOAT(15,2), BRENT_Managed_Money_Long FLOAT(15,2),WTI_Managed_Money_Short FLOAT(15,2),BRENT_Managed_Money_Short FLOAT(15,2),created TIMESTAMP DEFAULT CURRENT_TIMESTAMP, \\\n",
    "                                        PRIMARY KEY(MDATE));\")\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Parse information with Beautifulsoup and Regex python librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017-12-05', None, None, None, None, 392431.0, None, 439751.0, None, 47320.0, None]\n"
     ]
    }
   ],
   "source": [
    "# On fait le test pour extraire la donnee que l'on cherche du rapport du cftc\n",
    "import csv\n",
    "import urllib2\n",
    "import re\n",
    "from urllib2 import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "html = urlopen(\"http://www.cftc.gov/dea/options/petroleum_lof.htm\")\n",
    "bsObj = BeautifulSoup(html.read())\n",
    "text = []\n",
    "index = 0\n",
    "#test = bsObj.find(\"pre\",re.compile(\"[Code-02165E]+\"))\n",
    "test2 = bsObj.findAll(\"pre\")\n",
    "\n",
    "for item in test2:\n",
    "    if 'txt' in item:\n",
    "        # Add the date and reports\n",
    "        text.append(test2[index-1])\n",
    "    index += 1\n",
    "    \n",
    "test = bsObj.prettify()\n",
    "\n",
    "line_re = re.compile('(Code-02165E)\\w+')\n",
    "\n",
    "#records = line_re.find(test)\n",
    "#for item in test2[0]:\n",
    "#    print item\n",
    "#records\n",
    "\n",
    "mysrch = re.search('(Code-067651)+',test)\n",
    "mysrch2 = re.search('(Code-067657)+',test)\n",
    "\n",
    "tableNYMEX = test[mysrch.start():mysrch2.start()]\n",
    "\n",
    "entries = re.split(\"\\n+\", tableNYMEX)\n",
    "\n",
    "\n",
    "#On va mettre les donnees dans une nouvelle list en format float pour etre ensuite integrees dans la BDD\n",
    "sep = re.sub(\" \",\";\",entries[10])\n",
    "sep = re.sub(\":\",\";\",sep)\n",
    "sep = re.split(';',sep)\n",
    "sep2 = []\n",
    "for item in sep:\n",
    "\n",
    "    if item not in [\" \",\"\",\"u''\",None,\"All\"]:\n",
    "        sep2.append(float(re.sub(\",\",\"\",item)))\n",
    "        \n",
    "# Il faut recuperer la date a laquelle les positions sont entrees\n",
    "import dateutil.parser as dparser\n",
    "import datetime\n",
    "date = dparser.parse(entries[1],fuzzy=True)\n",
    "\n",
    "date = date.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "dtemp =[]\n",
    "\n",
    "for i in range(10):\n",
    "    if i==0:\n",
    "        dtemp.append(date)\n",
    "    if i==6:\n",
    "        dtemp.append(sep2[6])\n",
    "    elif i==8:\n",
    "        dtemp.append(sep2[7])\n",
    "    elif i==4:\n",
    "        dtemp.append(sep2[6]-sep2[7])\n",
    "    else:\n",
    "        dtemp.append(None)\n",
    "        \n",
    "print dtemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Let's store the list in our DB using SQL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "conn = pymysql.connect(host='127.0.0.1', user='Baptiste',passwd='Kamca2016!', db='scraping')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"USE scraping\")\n",
    "\n",
    "#On rentre les donnees dans la BDD\n",
    "sql = 'INSERT INTO volume_oi (MDATE,FUT_AGGTE_VOL_BRENT,BRENT_1,BRENT_OI,WTI_OI,WTI_Managed_Money_Net,BRENT_Managed_Money_Net,WTI_Managed_Money_Long,BRENT_Managed_Money_Long,WTI_Managed_Money_Short,BRENT_Managed_Money_Short) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\\\n",
    "                          ON DUPLICATE KEY UPDATE MDATE=VALUES(MDATE);'\n",
    "\n",
    "cur.execute(sql,dtemp)    \n",
    "    \n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Conclusion:\n",
    "\n",
    "- We need to run the query everyweek as link given is for latest report only\n",
    "- We illustrate information in a separate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
